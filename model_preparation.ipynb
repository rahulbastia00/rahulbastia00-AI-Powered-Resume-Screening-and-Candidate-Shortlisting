{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0986e62e-8e6f-4d04-8f28-8ebb531de324",
   "metadata": {},
   "source": [
    "# Data collection and preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c21953d8-2188-499e-abe5-387ff0ea7956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract text from resumes\n",
    "from pdfminer.high_level import extract_text\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    return extract_text(pdf_path)\n",
    "pdf_text = extract_text_from_pdf(\"C:/Users/rahul/OneDrive/Desktop/rahul-bastia_cvpdf.pdf\")\n",
    "# print(pdf_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69126634-22be-4024-8e4a-9b36b6580e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "def extract_text_from_docx(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "docx_text = extract_text_from_docx(\"C:/Users/rahul/OneDrive/Desktop/rahul-bastia_cv.docx\")\n",
    "# print(docx_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ce97b4-2426-4163-99ff-acdaa27140c8",
   "metadata": {},
   "source": [
    "# Text clening and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a20dd74-fad7-45b6-9bc8-284a1092460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "\n",
    "    # Tokenization and Lemmatization\n",
    "    doc = nlp(text)\n",
    "    cleaned_text = \" \".join([token.lemma_ for token in doc if token.text not in stopwords.words(\"english\")])\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "cleaned_resume_text = preprocess_text(docx_text)\n",
    "print(cleaned_resume_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b642ef36-d719-4f82-b49e-f05e1542b884",
   "metadata": {},
   "source": [
    "# Set Up MongoDB Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ace66fd-95f5-4cae-b0fe-50b6d5d4efe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InsertOneResult(ObjectId('6799ee66b2207b0a64d24537'), acknowledged=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "#connect to mongodb\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"resume_database\"]\n",
    "collection = db[\"resumes\"]\n",
    "\n",
    "# store processed resume\n",
    "resume_data = {\"name\": \"Candidate 1\", \"resume_text\" : cleaned_resume_text}\n",
    "collection.insert_one(resume_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75775a85-e297-46ff-90c8-9cff2431c562",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
