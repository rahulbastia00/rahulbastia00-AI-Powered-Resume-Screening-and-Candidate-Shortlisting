{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0986e62e-8e6f-4d04-8f28-8ebb531de324",
   "metadata": {},
   "source": [
    "# Data collection and preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c21953d8-2188-499e-abe5-387ff0ea7956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract text from resumes\n",
    "from pdfminer.high_level import extract_text\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    return extract_text(pdf_path)\n",
    "pdf_text = extract_text_from_pdf(\"C:/Users/rahul/OneDrive/Desktop/rahul-bastia_cvpdf.pdf\")\n",
    "# print(pdf_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69126634-22be-4024-8e4a-9b36b6580e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "def extract_text_from_docx(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    return \"\\t\".join([para.text for para in doc.paragraphs])\n",
    "docx_text = extract_text_from_docx(\"C:/Users/rahul/OneDrive/Desktop/rahul-bastia_cv.docx\")\n",
    "# print(docx_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ce97b4-2426-4163-99ff-acdaa27140c8",
   "metadata": {},
   "source": [
    "# Text clening and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a20dd74-fad7-45b6-9bc8-284a1092460d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rahul bastia leetcode rahulbastia email rahul bastia00 gmail com linkedin rahulbastia phone 91 6371480952 github rahulbastia00 experience hewlett packard enterprise jan 2025 software engineering virtual intern 25 remote write proposal restful web service manage list employee build web server application java spring boot accept respond http request well support upload json datum develop run set unit test assess java spring boot application performance walmart global tech jan 2025 advanced software engineering virtual intern 25 remote solved challenge technical project various walmart team develop novel java heap datum structure shipping department demonstrate strong problem solve algorithmic skill design uml class diagram er diagram datum processing database system showcasing proficiency software design principle project job board backend node js mongodb integration mongodb express js node js code build job portal secure jwt authentication restful api use node js express mongodb enable crud operation recruiter student company manage job post profile optimize backend datum security scalability use mongoose mongodb atlas cloud storage integration efficient datum management real time ride booking system llm langchain chroma db generative ai code build full stack uber clone use microservice architecture react tailwind css socket io real time update node js express js mongodb scalable backend integrate google maps api ride tracking design modular microservice implement jwt base authentication restful apis optimize database query mongoose develop dynamic ui component state management real time socket communication content recommendation system tmdb api python vectorization code build movie recommender system python streamlit tmdb api dynamic movie poster display apply vectorization efficient content base movie similarity scoring recommendation optimize recommendation retrieval precomputed similarity matrix responsive user experience education bachelor technology gandhi institute technology gift bhubaneswar expect 2026 cgpa 4th semester 7 54 technical skill programming language python java c c javascript sql tool framework node js react js mysql mongodb github docker lang chain linux core course datum structure algorithm operating system computer network database manegement system computer architecture object orient programming machine learn devop soft skill communication team work problem solve time management certification machine learn specialization stanford deeplearning ai mern stack apna collage extracurricular achievement lead mage finding robot competition lead organizer gift intercollegiate robotic competition winner internal hackathon smart india hackathon collage level 2024 solve 280 code challenge platform like leetcode gfg practice\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "\n",
    "    # Tokenization and Lemmatization\n",
    "    doc = nlp(text)\n",
    "    cleaned_text = \" \".join([token.lemma_ for token in doc if token.text not in stopwords.words(\"english\")])\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "cleaned_resume_text = preprocess_text(docx_text)\n",
    "print(cleaned_resume_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b642ef36-d719-4f82-b49e-f05e1542b884",
   "metadata": {},
   "source": [
    "# Set Up MongoDB Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ace66fd-95f5-4cae-b0fe-50b6d5d4efe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InsertOneResult(ObjectId('679b7aae3e4e4af92525c83f'), acknowledged=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "#connect to mongodb\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"resume_database\"]\n",
    "collection = db[\"resumes\"]\n",
    "\n",
    "# store processed resume\n",
    "resume_data = {\"name\": \"Candidate 1\", \"resume_text\" : cleaned_resume_text}\n",
    "collection.insert_one(resume_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383dd946",
   "metadata": {},
   "source": [
    "# NLP-Based Resume Parsing\n",
    "* Goal: Extract key information from resumes, such as skills, education, experience, and job titles, using Named Entity Recognition (NER) and embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75775a85-e297-46ff-90c8-9cff2431c562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q groq \n",
    "groq_api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "924c3eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Skills: Python, Java, C/C++, JavaScript, SQL, Node.js, React.js, MySQL, MongoDB, GitHub, Docker, Lang chain, Linux, Data Structure, Algorithms, Operating System, Computer Networks, Database Management System, Computer Architecture, Object-Oriented Programming, Machine Learning, DevOps, Communication, Team Work, Problem Solving, Time Management\n",
      "Extracted Experience: Software Engineering Virtual Intern at Hewlett Packard Enterprise, Advanced Software Engineering Virtual Intern at Walmart Global Tech\n",
      "Extracted Job Titles: Software Engineering Virtual Intern, Advanced Software Engineering Virtual Intern\n",
      "Extracted Education: Bachelor of Technology at Gandhi Institute For Technology (GIFT), Bhubaneswar\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "\n",
    "# It's better to store your API key in an environment variable\n",
    "groq_api_key = \"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\"  # Store your API key in an environment variable for security\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0,\n",
    "    groq_api_key=groq_api_key\n",
    ")\n",
    "\n",
    "# Make sure pdf_text is defined and contains the resume text\n",
    "pdf_text = extract_text_from_pdf(\"C:/Users/rahul/OneDrive/Desktop/rahul-bastia_cvpdf.pdf\")\n",
    "# Replace with the actual text extracted from the resume\n",
    "\n",
    "# Invoke the model to extract skills, experience, job titles, and education\n",
    "response = llm.invoke(f\"\"\"\n",
    "Here is the given text extracted from a resume: {pdf_text} \n",
    "Please extract the following information:\n",
    "- Skills\n",
    "- Experience\n",
    "- Job Titles\n",
    "- Education\n",
    "### Format the response as follows: ###\n",
    "Skills: [skill1, skill2, ...]\n",
    "Experience: [experience1, experience2, ...]\n",
    "Job Titles: [job_title1, job_title2, ...]\n",
    "Education: [degree1, degree2, ...]\n",
    "### No Preambles ###\n",
    "\"\"\")\n",
    "\n",
    "# Initialize empty strings to store skills, experience, job titles, and education\n",
    "skills_string = \"\"\n",
    "experience_string = \"\"\n",
    "job_titles_string = \"\"\n",
    "education_string = \"\"\n",
    "\n",
    "# Check if the response is valid\n",
    "if response and hasattr(response, 'content'):\n",
    "    # Assuming the response content is structured as requested\n",
    "    response_content = response.content.strip()\n",
    "    \n",
    "    # Split the response into lines\n",
    "    lines = response_content.split('\\n')\n",
    "    \n",
    "    # Extract skills, experience, job titles, and education from the response\n",
    "    for line in lines:\n",
    "        if line.startswith(\"Skills:\"):\n",
    "            skills_string = line.replace(\"Skills:\", \"\").strip()\n",
    "        elif line.startswith(\"Experience:\"):\n",
    "            experience_string = line.replace(\"Experience:\", \"\").strip()\n",
    "        elif line.startswith(\"Job Titles:\"):\n",
    "            job_titles_string = line.replace(\"Job Titles:\", \"\").strip()\n",
    "        elif line.startswith(\"Education:\"):\n",
    "            education_string = line.replace(\"Education:\", \"\").strip()\n",
    "else:\n",
    "    print(\"Error: Invalid response\")\n",
    "\n",
    "# Now you can access the extracted information as strings\n",
    "print(f\"Extracted Skills: {skills_string}\")\n",
    "print(f\"Extracted Experience: {experience_string}\")\n",
    "print(f\"Extracted Job Titles: {job_titles_string}\")\n",
    "print(f\"Extracted Education: {education_string}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb608949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Software Engineering Virtual Intern, Advanced Software Engineering virtual intern, Lead, Organizer\n"
     ]
    }
   ],
   "source": [
    "print(job_titles_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd2e86f",
   "metadata": {},
   "source": [
    "# Improve Skill Extraction with Predefined Skill List\n",
    "* We will match extracted text with a predefined skill database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8aecf00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted skills_string: ['Java', 'Algorithms', 'Kubernetes', 'GitHub', 'Python', 'Node.js', 'Docker', 'React']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load predefined skill set (example list)\n",
    "predefined_skills_string = {\"Python\", \"Machine Learning\", \"Deep Learning\", \"Java\", \"Docker\", \"Kubernetes\", \"React\", \"Node.js\", \"GitHub\", \"Algorithms\"}\n",
    "\n",
    "\n",
    "def extract_skills_string(skills_string):\n",
    "    words = set(skills_string.split())\n",
    "    matched_skills_string = predefined_skills_string.intersection(words)\n",
    "    return list(matched_skills_string)\n",
    "\n",
    "extracted_skills = extract_skills_string(skills_string)\n",
    "print(\"Extracted skills_string:\", extracted_skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486fc833",
   "metadata": {},
   "source": [
    "# Convert Resumes to Embeddings for Better Matching\n",
    "* To compare resume skills with job descriptions, we use sentence-transformers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ca393eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume embedding shape: (384,)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the sentence-transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def get_resume_embedding(text):\n",
    "    return model.encode(text)\n",
    "\n",
    "resume_embedding = get_resume_embedding(skills_string)\n",
    "print(\"Resume embedding shape:\", resume_embedding.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d42dcc",
   "metadata": {},
   "source": [
    "## Store Parsed Resumes in MongoDB\n",
    "** We will store structured resume information in MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd39a430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed resume stored in MongoDB!\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"resume_database\"]\n",
    "collection = db[\"parsed_resume\"]\n",
    "\n",
    "resume_data = {\n",
    "    \"name\": \"rahul\",\n",
    "    \"education\": education_string,\n",
    "    \"experience\": experience_string,\n",
    "    \"skills\": extracted_skills,\n",
    "    \"job_title\": job_titles_string,\n",
    "    \"embedding\": resume_embedding.tolist()\n",
    "}\n",
    "collection.insert_one(resume_data)\n",
    "print(\"Parsed resume stored in MongoDB!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
